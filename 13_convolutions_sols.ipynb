{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. What is a \"feature\"?__\n",
    "\n",
    "A data transformation that makes it easier to model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Write out the convolutional kernel matrix for a top edge detector.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_edge = tensor([[1,1,1],\n",
    "                   [ 0, 0, 0],\n",
    "                   [ -1, -1, -1]]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Write out the mathematical operation applied by a 3×3 kernel to a single pixel in an image.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication\n",
    "\n",
    "The cells in the kernel are mulitplied by a group of cells in the image. Then they are added together. This represents one conv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. What is the value of a convolutional kernel apply to a 3×3 matrix of zeros?__\n",
    "\n",
    "A zero matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. What is \"padding\"?__\n",
    "\n",
    "Padding allows us to apply a kernel to the corners of a image matrix. It 'pads' the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. What is \"stride\"?__\n",
    "\n",
    "Stride refers to how many pixels we move over after each kernel application. Stride-2 means we move over 2 pixels after a kernel application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Create a nested list comprehension to complete any task that you choose.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[(0, 0), (1, 0), (2, 0), (3, 0)],\n",
       "  [(0, 1), (1, 1), (2, 1), (3, 1)],\n",
       "  [(0, 2), (1, 2), (2, 2), (3, 2)]],\n",
       " [[(0, 0), (1, 0), (2, 0), (3, 0)],\n",
       "  [(0, 1), (1, 1), (2, 1), (3, 1)],\n",
       "  [(0, 2), (1, 2), (2, 2), (3, 2)]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[[(i,j) for i in range(4)] for j in range(3)] for _ in range(2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8. What are the shapes of the `input` and `weight` parameters to PyTorch's 2D convolution?__\n",
    "\n",
    "input shape: (minibatch, in_channels, iH, iW)\n",
    "weight shape: (out_channels, in_channels, kH, kW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__9. What is a \"channel\"?__\n",
    "\n",
    "A single basic color in an image. For RGB images there are three channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__10. What is the relationship between a convolution and a matrix multiplication?__\n",
    "\n",
    "They are the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__11. What is a \"convolutional neural network\"?__\n",
    "\n",
    "A series of matrix multiplications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__12. What is the benefit of refactoring parts of your neural network definition?__\n",
    "\n",
    "Reduces the likelihood of getting inconsistent shapes, etc in architectures\n",
    "\n",
    "Makes things clearer to the reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__13. What is `Flatten`? Where does it need to be included in the MNIST CNN? Why?__\n",
    "\n",
    "It's the equivalent of the squeeze function. But you can call `Flatten` as a module in `nn.Sequential`.\n",
    "\n",
    "It's included at the end of the MNIST CNN to convert a rank 4 tensor into a rank 2 tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__14. What does \"NCHW\" mean?__\n",
    "\n",
    "N,C,H,W = batch,channel,height,width\n",
    "\n",
    "For 64x1x28x28:\n",
    "\n",
    "batch = 64\n",
    "\n",
    "channel = 1\n",
    "\n",
    "height = 28\n",
    "\n",
    "width = 28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__15. Why does the third layer of the MNIST CNN have `7*7*(1168-16)` multiplications?__"
    "\n",
    "The number of weights is input_ch*output_ch*ks*ks, which is 8*16*3*3 = 1152. The total number of params reported is 1152+16=1168 because of the biases (input_ch*2). So the total multiplications are h*w*params = 7*7*(1168-16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__16. What is a \"receptive field\"?__\"\n",
    "\n",
    "The area of an image that is involved in the calculation of a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__17. What is the size of the receptive field of an activation after two stride 2 convolutions? Why?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 14)\n",
      "(7, 7)\n",
      "(4, 4)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "pad = 1\n",
    "ks = 3\n",
    "stride = 2\n",
    "\n",
    "def get_act_dim(height,width):\n",
    "    '''get activation map dimensions'''\n",
    "    def _calc(n): return (n + 2*pad - ks)//stride + 1\n",
    "    return _calc(height), _calc(width)\n",
    "\n",
    "layer1 = get_act_dim(28, 28); print(layer1)\n",
    "layer2 = get_act_dim(*layer1); print(layer2)\n",
    "layer3 = get_act_dim(*layer2); print(layer3)\n",
    "layer4 = get_act_dim(*layer3); print(layer4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size is: `(4, 4)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__18. Run *conv-example.xlsx* yourself and experiment with *trace precedents*.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__19. Have a look at Jeremy or Sylvain's list of recent Twitter \"like\"s, and see if you find any interesting resources or ideas there.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__20. How is a color image represented as a tensor?__\n",
    "\n",
    "`ch_out x ch_in x ks x ks`. When dealing with RGB images `ch_in` for the first conv  will be 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__21. How does a convolution work with a color input?__\n",
    "\n",
    "The RGB channels are treated separately. Each channel is multiplied by the kernel. These are added together for each grid location for each output feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__22. What method can we use to see that data in `DataLoaders`?__\n",
    "\n",
    "`show_batch()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__23. Why do we double the number of filters after each stride-2 conv?__\n",
    "\n",
    "A stride 2 conv with the default padding (1) and ks (3) will reduce the activation map dimension by half. Formula: `(n + 2*pad - ks)//stride + 1`. As the activation map dimension reduces by half we double the number of filters. This results in no overall change in computation as the network gets deeper and deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__24. Why do we use a larger kernel in the first conv with MNIST (with `simple_cnn`)?__\n",
    "\n",
    "Initially, the first conv in MNIST has ks of 3 and number of output filters of 8. \n",
    "\n",
    "This means the kernel has shape 3x3. So we are using 9 pixels to obtain 8 numbers. The output size and the input size is roughly the same. The network won't learn very much.\n",
    "\n",
    "As a result, we change the ks to 5. This results in a 5x5 kernel shape. So we're using 25 numbers to obtain 8 output numbers. This works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__25. What information does `ActivationStats` save for each layer?__\n",
    "\n",
    "ActivationStats saves information about the activations (mean, std, near zero %). They are indexed by layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__26. How can we access a learner's callback after training?__\n",
    "\n",
    "Use the learn object. Eg. `learn.activation_stats`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__27. What are the three statistics plotted by `plot_layer_stats`? What does the x-axis represent?__\n",
    "\n",
    "mean, std, near zero %\n",
    "\n",
    "The x-axis represent the evolution over time, i.e. the number of batches trained so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__28. Why are activations near zero problematic?__\n",
    "\n",
    "Multiplying a small number by a small number gives a very small number. As the number of mupltication tends toward infinity, the activations will tend towards zero. These don't really help the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__29. What are the upsides and downsides of training with a larger batch size?__\n",
    "\n",
    "Upside: Larger batches have gradients that are more accurate, since they train on more data\n",
    "Downside: Fewer batches per epoch. Less time for the model to update weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__30. Why should we avoid using a high learning rate at the start of training?__\n",
    "\n",
    "We may reach diverge immediately and completely miss the minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__31. What is 1cycle training?__\n",
    "\n",
    "Consists of:\n",
    "- Warmup: lr grows from min value to max value\n",
    "- Annealing: lr decreases from max value to min value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__32. What are the benefits of training with a high learning rate?__\n",
    "\n",
    "Faster training (super-convergence)\n",
    "\n",
    "We overfit less because we skip over the sharp local minima to end up in a smoother (and therefore more generalizable) part of the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__33. What is \"cyclical momentum\"?__\n",
    "\n",
    "The optimizer takes a step in the direction of the gradients and also continues in the direction of previous steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__34. What callback tracks hyperparameter values during training (along with other information)?__\n",
    "\n",
    "`learn.recorder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__35. What does one column of pixels in the `color_dim` plot represent?__\n",
    "\n",
    "The histogram of activations for a single batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__36. What does \"bad training\" look like in `color_dim`? Why?__\n",
    "\n",
    "Bad training would show a non-smooth curve on the color_dim graph. This is indicative of the activations increasing then collapsing to become near zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__37. What trainable parameters does a batch normalization layer contain?__\n",
    "\n",
    "gamma weights, beta weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__38. What statistics are used to normalize in batch normalization during training? How about during validation?__\n",
    "\n",
    "During training we use the mean and std dev of the activations in a batch to normalize the data. \n",
    "\n",
    "During validation we use the running mean of the statistics calculated during training the normalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__39. Why do models with batch normalization layers generalize better?__\n",
    "\n",
    "Some researchers think that it adds some extra randomness to the training process. The mini-batch will have a different mean and std dev of activations compared to other mini-batches. As a result, the activations will be normalised by different values throughout training. The model becomes robust to these extra bits of randomness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
